## LDA-BERT-ABSA
This repository contains part of the code and pre-trained models for our paper "A LDA Model Augmented with BERT for Aspect Level Sentiment Analysis", which has been submitted to ICJAI024. The complete code will be released right after the conference announces the acceptance results.

## Contents
- Abstract
- Overview
- Datasets
- Baseline
- Train
- Results

## Abstract
Video-language pre-training has significantly improved the performance of diverse downstream tasks related to video and language. However, existing approaches often directly adapt image-language pre-training paradigms to video-language tasks, neglecting the unique temporal characteristics of videos. In this paper, we present a novel temporal-aware video-language pre-training framework. It introduces two innovative pre-training tasks to enhance temporal-awareness in multi-modal representations, incorporating fine-grained temporal moment information and temporal contextual relations between video-text pairs. Firstly, we propose a cross-modal moment exploration task, leveraging paired texts to uncover detailed video moment representations. Subsequently, using the acquired moment representations, we capture inherent temporal contextual relations by aligning video-text pairs across different time resolutions in a multi-modal temporal relation exploration task. Additionally, we introduce a shuffling test to assess the temporal reliance of datasets and the efficacy of video-language pre-training. This framework aims to fully exploit the temporal dimension in video data for more effective pre-training and improved downstream task performance.

## Overview

![image](https://github.com/kaamava/LDA-BERT-ABSA/assets/106901273/98e7b9ad-d455-41b8-b42d-17b45d2c2f52)




## Results
